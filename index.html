<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>üéôÔ∏è DiaChat - Voice Consistency Optimized</title>
  <style>
    /* (Your existing styles here) */
    body { font-family: sans-serif; background: #f0f0f0; }
    .container { max-width: 800px; margin: auto; padding: 1em; background: #fff; }
    .controls { display: flex; gap: 1em; margin-bottom: 1em; }
    .btn { padding: 0.5em 1em; cursor: pointer; }
    .status-box { border: 1px solid #ddd; padding: 0.5em; min-height: 2em; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è DiaChat</h1>
    <div class="controls">
      <button id="startBtn" class="btn">Start Listening</button>
      <button id="stopBtn" class="btn" disabled>Stop</button>
    </div>
    <div id="status" class="status-box">Ready</div>
    <div id="whisperStatus" class="status-box">Waiting for speech...</div>
    <div id="ttsStatus" class="status-box">Waiting for AI response...</div>
    <div id="chatLog" class="status-box" style="min-height:6em; overflow-y:auto;"></div>
  </div>

  <script>
    let ws, audioCtx, sourceNode, isRecording = false;
    const startBtn = document.getElementById("startBtn");
    const stopBtn  = document.getElementById("stopBtn");
    const status   = document.getElementById("status");
    const whisperStatus = document.getElementById("whisperStatus");
    const ttsStatus     = document.getElementById("ttsStatus");
    const chatLog       = document.getElementById("chatLog");

    window.addEventListener('load', () => {
      audioCtx = new AudioContext({ sampleRate: 48000 });
    });

    function updateStatus(text) { status.textContent = text; }
    function updateWhisper(text) { whisperStatus.textContent = text; }
    function updateTTS(text)     { ttsStatus.textContent     = text; }
    function addChat(sender, msg) {
      const div = document.createElement('div');
      div.innerHTML = `<strong>${sender}:</strong> ${msg}`;
      chatLog.appendChild(div);
      chatLog.scrollTop = chatLog.scrollHeight;
    }

    function startRecording() {
      updateStatus("Connecting...");
      ws = new WebSocket(`${location.origin.replace(/^http/, 'ws')}/ws/audio`);
      ws.binaryType = 'arraybuffer';

      ws.onopen = async () => {
        updateStatus("Listening...");
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const src    = audioCtx.createMediaStreamSource(stream);
        const proc   = audioCtx.createScriptProcessor(4096, 1, 1);

        proc.onaudioprocess = (e) => {
          if (!isRecording) return;
          const input = e.inputBuffer.getChannelData(0);
          const pcm16 = new Int16Array(input.length);
          for (let i=0; i<input.length; i++)
            pcm16[i] = Math.max(-32768, Math.min(32767, input[i]*32768));
          ws.send(pcm16.buffer);
        };

        src.connect(proc);
        proc.connect(audioCtx.destination);
        isRecording = true;
        startBtn.disabled = true;
        stopBtn.disabled  = false;
      };

      ws.onmessage = async event => {
        if (event.data instanceof ArrayBuffer) {
          // decode raw PCM16 buffer
          const pcmBuffer = event.data;
          const frameCount = pcmBuffer.byteLength / 2;
          const audioBuffer = audioCtx.createBuffer(1, frameCount, 48000);
          const chan = audioBuffer.getChannelData(0);
          const dv = new DataView(pcmBuffer);
          for (let i = 0; i < frameCount; i++) {
            chan[i] = dv.getInt16(i*2, true) / 32768;
          }
          sourceNode = audioCtx.createBufferSource();
          sourceNode.buffer = audioBuffer;
          sourceNode.connect(audioCtx.destination);
          sourceNode.start();
        } else {
          const msg = JSON.parse(event.data);
          switch(msg.type) {
            case 'text':         addChat('You', msg.payload); break;
            case 'ai_response':  addChat('AI',  msg.payload); break;
            case 'whisper_status': updateWhisper(msg.payload); break;
            case 'tts_status':     updateTTS(msg.payload); break;
          }
        }
      };

      ws.onerror = () => updateStatus("Connection error");
      ws.onclose = () => updateStatus("Disconnected");
    }

    function stopRecording() {
      isRecording = false;
      startBtn.disabled = false;
      stopBtn.disabled  = true;
      if (ws) ws.close();
      updateStatus("Stopped");
    }

    startBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);
  </script>
</body>
</html>
